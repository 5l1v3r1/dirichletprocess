---
title: "Dirichlet Process"
author: "Dean Markwick"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Dirichlet Process}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r, include=FALSE}
library(dirichletprocess)
library(ggplot2)
library(tidyr)
library(dplyr)
library(mvtnorm)

kottas_weibull <- function(x, theta) {
  alpha = theta[[1]][,,,drop=TRUE]
  lambda = theta[[2]][,,,drop=TRUE]
  
  y <- lambda^(-1) * alpha * x^(alpha-1) * exp(-lambda^(-1) * x^alpha)
  return(y)
}

```

```{r}
its <- 10
```
In this vignette we will be demonstrating the various uses that the dirichletprocess package provides. For speed purposes the variable `its` is set to a low number. Increase it to 250+ for the full results. 


```{r, eval=FALSE}
y <- rt(200, 3) + 2
dp <- DirichletProcessGaussian(y)
dp <- Fit(dp, its)
plot(dp, single=TRUE)
```




### Old Faithful

The Dirichlet Process can be used to fit non-parametric distributions to data. In this example we will show how the `oldfaithful` data can be modelled using Dirichlet process. 

```{r oldfaithful plot, fig.align='center'}
ggplot(faithful, aes(x=waiting)) + geom_histogram(bins=20)
```

We model this data using the default specifications of the Gaussian Dirichlet Process function. This is adequate for our transformed data. 

```{r oldfaithful dp, fig.show='hold'}
faithfulTransformed = (faithful$waiting - mean(faithful$waiting))/sd(faithful$waiting)

dpobj = DirichletProcessGaussian(faithfulTransformed)

dpobj = Fit(dpobj, its)

old_faithful_plot <- plot(dpobj)
print(old_faithful_plot)
qplot(seq_along(dpobj$alphaChain), dpobj$alphaChain, geom="line")
```


### Density estimation on a bounded interval
We also include the ability to estimate densities on a bounded interval using a Beta distribution mixture model. We simulate some test data from a known mixture of Beta distributions and fit our Beta DP to it. 
```{r simulate data}
y <- c(rbeta(100, 1, 3), rbeta(100, 7, 3))

beta_dpobj <- DirichletProcessBeta(y, 1, mhStep = c(0.06, 0.06))
beta_dpobj <- Fit(beta_dpobj, its, TRUE)
plot(beta_dpobj)
```

```{r}
xGrid <- seq(0, 1, by=0.01)

betaRes <- data.frame(x=xGrid, Estimate=PosteriorFunction(beta_dpobj)(xGrid), Actual=0.5*dbeta(xGrid, 1, 3)+0.5*dbeta(xGrid, 7,3))

betaRes %>% gather(Key, Value, -x) %>% ggplot(aes(x=x, y=Value, colour=Key)) + geom_line()

```


### Non Conjugate Mixtures
Weibull Kottas example.

```{r weibull fit}
burnin = its/2
y1 <- rlnorm(160, 0, sqrt(0.25))
y2 <- rlnorm(40, 1.2, sqrt(0.02))
y <- c(y1, y2)

weib_dpobj <- DirichletProcessWeibull(y/max(y), c(3, 2, 0.01), mhStepSize = 0.06, verbose=TRUE)
weib_dpobj <- Fit(weib_dpobj, its, TRUE)

plot(weib_dpobj, single = FALSE)
plot(weib_dpobj, single = TRUE)
```



### Poisson Intensity Estimation

Dirichlet processes can be used to estimate the interesting function of an inhomogeneous Poisson process. Here we simulate from a periodic intensity function and estimate such function using a Generalised Beta distribution bounded on the maximum time.  

```{r sin mixture sim}
y <- cumsum(runif(1000))

pdf <- function(x) sin(x/50)^2
accept_prob <- pdf(y)
pts <- sample(y, 500, prob=accept_prob)
```

```{r sin dp, fig.align='center'}
beta_dpobj <- DirichletProcessBeta(pts, max(pts)*1.01)
beta_dpobj <- Fit(beta_dpobj, its)

plot(beta_dpobj)  
```

Here we can see the fitted density aligns with the true density of the points. We then use the estimated density to calculate the estimated intensity function.  

```{r, echo=FALSE, fig.align='center'}
x_grid <- seq(0, max(pts)*1.01)
post_func_eval <- LikelihoodFunction(beta_dpobj)(x_grid)
post_func_eval <- post_func_eval / max(post_func_eval)

poissonFuncDF <- data.frame(x=x_grid, actual=pdf(x_grid), estimate=post_func_eval)
poissonFuncDF <- gather(poissonFuncDF, Type, Value, -x)

ggplot(poissonFuncDF, aes(x=x, y=Value, colour=Type)) + geom_line()
```
Here the estimated intensity function is very close to the true generating function. 


### Censored Weibull Inference
We can also adapt our Dirichlet process to analyse censored data. Censor data consists of the observations, with a indicator variable showing whether the value is censored.
```{r}
data_a <- c(1, 3 ,3, 6, 7, 7, 10, 12, 14, 15, 18 ,19, 22 ,26 , 28 , 29 ,34, 40, 48 ,49)
data_a <- 1 + (data_a / max(data_a))
data_a <- cbind(data_a, c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1))
data_b <- c(1, 1, 2, 2,3,4,5,8,8,9,11,12,14,16,18,21,27,31,38, 44)
data_b <- 1 + (data_b / max(data_b))
data_b <- cbind(data_b, c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0))
```
For this, we write a new likelihood and construct a new Dirichlet Process object. 
```{r}
Likelihood.weibullcens <- function(mdobj, x, theta){
  alpha = theta[[1]][,,,drop=TRUE]
  lambda = theta[[2]][,,,drop=TRUE]
  
  y <- as.numeric(lambda^(-1) * alpha * x[,1]^(alpha-1) * exp(-lambda^(-1) * x[, 1]^alpha))
  y_cens <- as.numeric(1 - exp(-x[,1]^alpha / lambda))
  
  if(nrow(x) == 1){
    if(x[,2] == 0) return(y)
    if(x[,2] == 1) return(y_cens)
  }
  else{
    y_ret <- y
    y_ret[x[,2] == 1] <- y_cens[x[,2]==1]
    return(y_ret)
  }
  
}

mdobj <- MixingDistribution("weibullcens", c(1,2,1), "nonconjugate", mhStepSize=c(0.11,0.11), hyperPriorParameters=c(2,2,1,0.1))

class(mdobj) <- c("list", "weibullcens", "weibull", "nonconjugate")

```



```{r}
treat_a_dpobj <- DirichletProcessCreate(data_a, mdobj, c(2, 0.9))
treat_a_dpobj <- Initialise(treat_a_dpobj)

treat_b_dpobj <- DirichletProcessCreate(data_b, mdobj, c(2, 0.9))
treat_b_dpobj <- Initialise(treat_b_dpobj)

treat_a_dpobj <- Fit(treat_a_dpobj, its, TRUE)
treat_b_dpobj <- Fit(treat_b_dpobj, its, TRUE)
```

```{r, echo=FALSE}
index_chain <- seq(round(its/2), its, length.out = 10)

PosteriorFunction_list = lapply(index_chain, function(i) PosteriorClusters(treat_a_dpobj, i))
PosteriorFunction_list_b = lapply(index_chain, function(i) PosteriorClusters(treat_b_dpobj, i))

x_grid = seq(1, 2.5, by=0.01)

kottas_weibull <- function(x, theta) {
  alpha = theta[[1]][,,,drop=TRUE]
  lambda = theta[[2]][,,,drop=TRUE]
  
  y <- lambda^(-1) * alpha * x^(alpha-1) * exp(-lambda^(-1) * x^alpha)
  return(y)
}

kottas_weibull_survival <- function(x, theta){
  alpha = theta[[1]][,,,drop=TRUE]
  lambda = theta[[2]][,,,drop=TRUE]
  
  y <-  1-exp(-x^alpha / lambda)
  return(y)
}


kottas_weibull_hazard <- function(x, theta){
  
  y <- kotta_weibull(x, theta)/kottas_weibull_survival(x, theta)
  return(y)
}

treat_a_mean_density <- rowMeans(data.frame(lapply(PosteriorFunction_list, function(x) weighted_function_generator(kottas_weibull, x$weights, x$params)(x_grid))))
treat_b_mean_density <- rowMeans(data.frame(lapply(PosteriorFunction_list_b, function(x) weighted_function_generator(kottas_weibull, x$weights, x$params)(x_grid))))

treat_a_mean_survival <- rowMeans(data.frame(lapply(PosteriorFunction_list, function(x) weighted_function_generator(kottas_weibull_survival, x$weights, x$params)(x_grid))))
treat_b_mean_survival <- rowMeans(data.frame(lapply(PosteriorFunction_list_b, function(x) weighted_function_generator(kottas_weibull_survival, x$weights, x$params)(x_grid))))

treat_a_hazard <- treat_a_mean_density / (1-treat_a_mean_survival)
treat_b_hazard <- treat_b_mean_density / (1-treat_b_mean_survival)

```


```{r, fig.align='center'}
x_grid_a <- (x_grid -1)*49
x_grid_b <- (x_grid -1)*44

treatmeant_df_a <- data.frame(A_Density=treat_a_mean_density, A_Survival=1-treat_a_mean_survival, A_Hazard=treat_a_hazard, x=x_grid_a)

treatmeant_df_b <- data.frame(B_Density=treat_b_mean_density, B_Survival=1-treat_b_mean_survival, B_Hazard=treat_b_hazard, x=x_grid_b)

treatmeant_df <- bind_rows(gather(treatmeant_df_a, label, value, -x), gather(treatmeant_df_b, label, value, -x))

treatmeant_df$Group = sapply(treatmeant_df$label, function(x) strsplit(x, "_")[[1]][1])
treatmeant_df$Function = sapply(treatmeant_df$label, function(x) strsplit(x, "_")[[1]][2])

treatmeant_df %>% filter(Function==c("Density", "Survival", "Hazard")) %>% ggplot(aes(x=x, y=value, colour=Group, group=Group)) + geom_line() + facet_wrap(~Function, scales = "free") + theme(legend.position = "bottom") -> weibull_censor_graph

print(weibull_censor_graph)
```


### Clustering with Multivariate Normal
Dirichlet Process also have clustering applications. Here we demonstrate this by simulating from a two dimensional Gaussian distribution and fitting a Dirichlet process. Using the component labels we can assign the data into appropriate clusters. 


```{r clustering}
y <- rbind(rmvnorm(30, c(7,10), diag(2)-0.1), rmvnorm(30, c(1,2), diag(2)+0.1)) 

dpobj <- DirichletProcessMvnormal(y)

dt <- data.frame(x=y[,1], y=y[,2], label=as.factor(dpobj$clusterLabels), fit="N")

dpobj <- Fit(dpobj, its)
```


```{r, echo=FALSE,  fig.show='hold'}
dt <- rbind(dt, data.frame(x=y[,1], y=y[,2], label=as.factor(dpobj$clusterLabels), fit="Y"))

clustering_initial_plot <- ggplot(filter(dt, fit=="N"), aes(x=x, y=y, colour=label)) + geom_point() + guides(colour=FALSE)
clustering_fit_plot <- ggplot(filter(dt, fit=="Y"), aes(x=x, y=y, colour=label)) + geom_point() + guides(colour=FALSE)
print(clustering_initial_plot)
print(clustering_fit_plot)
```

Here we can see that starting initially with random clusters the data separates itself into the correct generating clusters. 





### Hierarchical Dirichlet Process

Lets consider two intensity functions that have a common component. 

```{r}
mu <- c(0.25, 0.75, 0.4)
tau <- c(5, 6, 10)

a <- mu*tau
b <- (1-mu)*tau

y1 <- c(rbeta(100, a[1], b[1]), rbeta(100, a[2], b[2]))
y2 <- c(rbeta(100, a[1], b[1]), rbeta(100, a[3], b[3]))


```


```{r}
dpobjlist <- DirichletProcessHierarchicalBeta(list(y1,y2), maxY=1, hyperPriorParameters = c(1, 0.01), mhStepSize = c(0.1, 0.1), gammaPriors = c(2, 4), alphaPriors = c(2, 4))

dpobjlist <- Fit(dpobjlist, its, TRUE)


plot(dpobjlist$indDP[[1]])
plot(dpobjlist$indDP[[2]])

xGrid <- seq(0, 1, by=0.01) 

plot(xGrid, 0.5*dbeta(xGrid, a[1], b[1]) + 0.5*dbeta(xGrid, a[2], b[2]), type="l")
lines(xGrid, PosteriorFunction(dpobjlist$indDP[[1]])(xGrid), col="red")
plot(xGrid, 0.5*dbeta(xGrid, a[1], b[1]) + 0.5*dbeta(xGrid, a[3], b[3]), type="l")
lines(xGrid, PosteriorFunction(dpobjlist$indDP[[2]])(xGrid), col="red")


```


### Normal Fixed Effects

For our model we have $y_i \sim N(\mu _i , \sigma ^2)$ where there is a basic regression structure on $\mu_i = \sum _j \beta _j x_{ji}$. Our prior on $\beta$ is a DP $\beta \sim G, G \sim \text{DP} (\alpha, G_0)$. 

Lets simulate some data. An intercept and two other components.

```{r}
nIndvs <- 1000

beta0 <- rnorm(nIndvs, 3, 0)
beta1 <- rnorm(nIndvs, 1, 0)
beta2 <- rnorm(nIndvs, -2, 0)

betaMat <- cbind(beta0[1], beta1[1], beta2[1])
xMat <- cbind(rep_len(1, nIndvs), rnorm(nIndvs, 5), rnorm(nIndvs, -5))

mu <- xMat %*% t(betaMat)

sigma <- 3
y <- rnorm(nIndvs, mu, sigma)

plot(density(y))
plot(density(mu))

mle <- optim(c(0.5, 0.5,0.5), function(x) -sum(dnorm(y, xMat %*% x, sigma)))

```

To infer what the parameters are in a non-DP case we would do the following with uninformative priors. 

If we pool all the data togehter.
```{r}
beatHat <- solve(t(xMat) %*% xMat)%*%t(xMat)%*%y
lambda0 <- diag(1, nrow = 3, ncol=3)
mu0 <- c(0,0,0)

mu_n <- solve(t(xMat) %*% xMat + lambda0) %*% (lambda0 %*% mu0 + t(xMat)%*%y)
lambda_n <- t(xMat) %*% xMat + lambda0
covMat <- solve(lambda_n)

smps <- replicate(1000, rnorm(3, mu_n, diag(covMat)*3))
rowMeans(smps)
```

```{r}





```


